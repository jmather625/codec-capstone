{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.DCVC_net import DCVC_net\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import tqdm\n",
    "import torchnet.meter as meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ishaan/College/Spring 2022/Codec/codec-capstone/DCVC_vbr/DCVC-Old/wandb/run-20220510_040556-3ntr7zs9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/codec-crew/DCVC-Variable-Quantization/runs/3ntr7zs9\" target=\"_blank\">experiment-variable-quantization-2048-local</a></strong> to <a href=\"https://wandb.ai/codec-crew/DCVC-Variable-Quantization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LAMBDA = 2048\n",
    "BATCH_SIZE = 4\n",
    "DATA_DIR1 = pathlib.Path('.//vimeo_septuplet/sequences')  #pathlib.Path('PATH')\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "\n",
    "video_net = DCVC_net()\n",
    "\n",
    "# Freeze parameters\n",
    "# for p in video_net.mvEncoder.parameters():\n",
    "#     p.requires_grad = False\n",
    "# for p in video_net.contextualEncoder.parameters():\n",
    "#     p.requires_grad = False\n",
    "# for p in video_net.priorEncoder.parameters():\n",
    "#     p.requires_grad = False\n",
    "# for p in video_net.mvpriorEncoder.parameters():\n",
    "#     p.requires_grad = False\n",
    "\n",
    "chpt = torch.load('./checkpoints/model_dcvc_quality_3_psnr.pth')\n",
    "video_net.load_state_dict(chpt)\n",
    "video_net = video_net.to(DEVICE)\n",
    "\n",
    "expirement_name = f\"experiment-variable-quantization-{LAMBDA}-local\"\n",
    "\n",
    "wandb.init(\n",
    "    project=\"DCVC-Variable-Quantization\", \n",
    "    # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "    name=expirement_name, \n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"architecture\": \"DCVC\",\n",
    "    \"dataset\": \"Vimeo-90k\",\n",
    "    \"epochs\": 20,\n",
    "    \"resume\": True\n",
    "})\n",
    "\n",
    "optimizer = torch.optim.Adam(video_net.parameters(), lr=wandb.config.learning_rate)\n",
    "del chpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vimeo_septuplet/sequences/00001/0291\n",
      "vimeo_septuplet/sequences/00001/0622\n",
      "vimeo_septuplet/sequences/00001/0278\n",
      "vimeo_septuplet/sequences/00001/0285\n",
      "vimeo_septuplet/sequences/00001/0268\n",
      "vimeo_septuplet/sequences/00001/0266\n",
      "vimeo_septuplet/sequences/00001/0287\n",
      "vimeo_septuplet/sequences/00001/0619\n",
      "vimeo_septuplet/sequences/00001/0275\n",
      "The model has 7944448 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir1, crop_size=256, make_b_cut=True, deterministic=False):\n",
    "        self.data_dir1 = data_dir1\n",
    "        self.crop_size = crop_size\n",
    "        self.make_b_cut = make_b_cut\n",
    "        self.deterministic = deterministic\n",
    "        self.all_paths = []\n",
    "        for seq in os.listdir(self.data_dir1):\n",
    "            subseq = os.listdir(self.data_dir1 / seq)\n",
    "            for s in subseq:\n",
    "                print(self.data_dir1 / seq / s)\n",
    "                self.all_paths.append(self.data_dir1 / seq / s)\n",
    "        # assert len(self.all_paths) == 91701\n",
    "        \n",
    "        self.transforms = torch.nn.Sequential(\n",
    "            transforms.RandomCrop(crop_size)\n",
    "        )\n",
    "       \n",
    "    def __getitem__(self, i):\n",
    "        path = self.all_paths[i]\n",
    "        imgs = []\n",
    "        '''\n",
    "        if self.make_b_cut:\n",
    "            # load two reference frames and the B-frame in the middle\n",
    "            #TODO: implement making this deterministic\n",
    "            interval = np.random.randint(1, 4) # can be 1, 2, or 3\n",
    "            ref1 = plt.imread(path / f'im{1}.png')\n",
    "            ref2 = plt.imread(path / f'im{1 + interval*2}.png')\n",
    "            # this is the B-frame, in the middle\n",
    "            im = plt.imread(path / f'im{1 + interval}.png')\n",
    "            imgs = [ref1, ref2, im]\n",
    "        else:\n",
    "        '''\n",
    "        '''\n",
    "        # load full sequence\n",
    "        for i in range(1, 8):\n",
    "            # should be between [0, 1]\n",
    "            img = plt.imread(path / f'im{i}.png')\n",
    "            imgs.append(img)\n",
    "        '''\n",
    "        \n",
    "        ref = plt.imread(path / f'im1.png')\n",
    "        im = plt.imread(path /\tf'im2.png')\n",
    "        imgs = [ref, im]        \n",
    "\n",
    "        # plt.imread should make inputs in [0, 1] for us\n",
    "        imgs = np.stack(imgs, axis=0)\n",
    "        # bring RGB channels in front\n",
    "        imgs = imgs.transpose(0, 3, 1, 2)\n",
    "        return self.transforms(torch.FloatTensor(imgs))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_paths)\n",
    "\n",
    "ds = VideoDataset(DATA_DIR1)\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    ds,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Return number of parameters in a model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(video_net)} trainable parameters')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, dl, optimizer, criterion, use_lambda=True):\n",
    "    model.train()\n",
    "\n",
    "    loss_meter = meter.AverageValueMeter()\n",
    "    mse_meter = meter.AverageValueMeter()\n",
    "    bpp_meter = meter.AverageValueMeter()\n",
    "    bpp_mv_y_meter = meter.AverageValueMeter()\n",
    "    bpp_mv_z_meter = meter.AverageValueMeter()\n",
    "    bpp_y_meter = meter.AverageValueMeter()\n",
    "    bpp_z_meter = meter.AverageValueMeter()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    pbar = tqdm.tqdm(dl)\n",
    "    for i, x in enumerate(pbar):\n",
    "        x = x.to(DEVICE)\n",
    "        ref1 = x[:,0]\n",
    "        #ref2 = x[:,1]\n",
    "        im = x[:,1]\n",
    "        preds_dict = model(ref1, im)\n",
    "        preds = preds_dict['recon_image']\n",
    "        bpp = preds_dict['bpp']\n",
    "        mse_loss = criterion(preds, im)\n",
    "        mse_ls = mse_loss.item()\n",
    "        avg_mse = mse_meter.value()[0]\n",
    "        if use_lambda:\n",
    "            loss = mse_loss * LAMBDA + bpp\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ls = loss.item()\n",
    "        loss_meter.add(ls)\n",
    "        mse_meter.add(mse_ls)\n",
    "        bpp_meter.add(bpp.item())\n",
    "        bpp_mv_y_meter.add(preds_dict['bpp_mv_y'].item())\n",
    "        bpp_mv_z_meter.add(preds_dict['bpp_mv_z'].item())\n",
    "        bpp_y_meter.add(preds_dict['bpp_y'].item())\n",
    "        bpp_z_meter.add(preds_dict['bpp_z'].item())\n",
    "        if i % 1 == 0:\n",
    "            avg_psnr = -10.0*np.log10(mse_meter.value()[0])\n",
    "            wandb.log(\n",
    "                {\n",
    "                    'train/epoch': epoch,\n",
    "                    'train/batch_loss': ls,\n",
    "                    'train/avg_loss': loss_meter.value()[0],\n",
    "                    'train/avg_mse_loss': mse_meter.value()[0],\n",
    "                    'train/avg_bpp': bpp_meter.value()[0],\n",
    "                    'train/avg_bpp_mv_y': bpp_mv_y_meter.value()[0],\n",
    "                    'train/avg_bpp_mv_z': bpp_mv_z_meter.value()[0],\n",
    "                    'train/avg_bpp_y': bpp_y_meter.value()[0],\n",
    "                    'train/avg_bpp_z': bpp_z_meter.value()[0],\n",
    "                    'train/avg_psnr': avg_psnr,\n",
    "                }\n",
    "            )\n",
    "            ls = round(ls, 6)\n",
    "            avg_bitrate = round(bpp_meter.value()[0], 6)\n",
    "            avg_psnr = round(avg_psnr, 6)\n",
    "            pbar.set_description(f'Avg PSNR/Bitrate, Batch Loss: {avg_psnr, avg_bitrate, ls}')\n",
    "\n",
    "    return loss_meter.value()[0], False, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg PSNR/Bitrate, Batch Loss: (42.596586, 0.054241, 0.290059): 100%|██████████| 9/9 [01:34<00:00, 10.52s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (42.68549, 0.053809, 0.096833): 100%|██████████| 9/9 [01:21<00:00,  9.05s/it] \n",
      "Avg PSNR/Bitrate, Batch Loss: (41.837742, 0.060076, 0.111628): 100%|██████████| 9/9 [01:19<00:00,  8.87s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (42.863766, 0.059353, 0.1041): 100%|██████████| 9/9 [01:18<00:00,  8.74s/it]  \n",
      "Avg PSNR/Bitrate, Batch Loss: (42.413106, 0.067534, 0.071266): 100%|██████████| 9/9 [01:18<00:00,  8.75s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (41.592343, 0.075367, 0.243876): 100%|██████████| 9/9 [01:18<00:00,  8.75s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (42.056497, 0.078416, 0.044493): 100%|██████████| 9/9 [01:18<00:00,  8.75s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (43.194841, 0.064473, 0.11833): 100%|██████████| 9/9 [01:18<00:00,  8.75s/it] \n",
      "Avg PSNR/Bitrate, Batch Loss: (42.530699, 0.085155, 0.248313): 100%|██████████| 9/9 [01:18<00:00,  8.76s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (42.633594, 0.086626, 0.18787): 100%|██████████| 9/9 [01:18<00:00,  8.76s/it] \n",
      "Avg PSNR/Bitrate, Batch Loss: (42.664004, 0.08823, 0.079829): 100%|██████████| 9/9 [01:18<00:00,  8.76s/it] \n",
      "Avg PSNR/Bitrate, Batch Loss: (42.317262, 0.094724, 0.146881): 100%|██████████| 9/9 [01:18<00:00,  8.77s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (43.14265, 0.097803, 0.075527): 100%|██████████| 9/9 [01:18<00:00,  8.75s/it] \n",
      "Avg PSNR/Bitrate, Batch Loss: (42.341744, 0.117308, 0.150291): 100%|██████████| 9/9 [01:18<00:00,  8.75s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (42.528095, 0.118761, 0.247208): 100%|██████████| 9/9 [01:18<00:00,  8.76s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (43.234947, 0.124704, 0.303288): 100%|██████████| 9/9 [01:18<00:00,  8.74s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (42.900047, 0.145228, 0.359459): 100%|██████████| 9/9 [01:18<00:00,  8.76s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (42.562952, 0.162048, 0.292941): 100%|██████████| 9/9 [01:18<00:00,  8.75s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (42.406951, 0.176883, 0.310825): 100%|██████████| 9/9 [01:18<00:00,  8.76s/it]\n",
      "Avg PSNR/Bitrate, Batch Loss: (41.6214, 0.196998, 0.196612): 100%|██████████| 9/9 [01:18<00:00,  8.74s/it]  \n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "SAVE_FOLDER = pathlib.Path(expirement_name)\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "\n",
    "USE_LAMBDA = True\n",
    "for i in range(1, wandb.config.epochs + 1):\n",
    "    avg_loss, had_err, err_x = train_epoch(video_net, i, dl, optimizer, criterion, use_lambda=USE_LAMBDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/avg_bpp</td><td>▁▂▃▂▁▂▂▂▃▂▇▃▄▄▂▂▄▄▄▃▄▃▄▄▃▄▆▅▆▅▅▅▅▅▇▆▆▇██</td></tr><tr><td>train/avg_bpp_mv_y</td><td>▁▁▁▁▁▁▂▁▂▁▂▁▁▁▂▁▂▂▂▂▂▂▂▂▂▂▃▂▄▃▄▃▃▄▆▅▅▆█▇</td></tr><tr><td>train/avg_bpp_mv_z</td><td>▃▄█▃▃▂▁▃▆▂▃▂▇▄▁▃▇▃▅▄▄▄▆▃▅▅▄▄▄▂▁▃▄▃▄▄▃▃▄▄</td></tr><tr><td>train/avg_bpp_y</td><td>▁▂▃▂▁▂▂▂▃▃█▃▄▄▂▃▄▄▄▄▄▃▄▄▃▄▆▅▅▄▄▃▄▄▄▄▄▃▄▄</td></tr><tr><td>train/avg_bpp_z</td><td>▁▃▄▄▂▃▂▃▄▃█▃▆▅▂▄▆▅▄▄▃▃▅▄▂▄▅▄▅▄▅▄▃▄▅▅▆▄▄▄</td></tr><tr><td>train/avg_loss</td><td>▁▂▂▂▁▂▂▂▃▂█▂▃▃▂▂▃▃▃▂▂▂▃▃▂▂▄▃▃▃▃▂▂▃▄▃▃▃▃▄</td></tr><tr><td>train/avg_mse_loss</td><td>▁▂▂▂▁▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▃▂▂▂▂▂▁▂▂▂▂▂▂▂</td></tr><tr><td>train/avg_psnr</td><td>█▆▅▆▇▅▆▆▅▆▁▅▅▅▆▆▅▅▆▅▆▇▆▅▇▆▄▅▅▆▆▆▇▆▅▆▅▆▆▅</td></tr><tr><td>train/batch_loss</td><td>▁▃▃▁▂█▂▃▃▂█▁▃▃▂▃▃▂▂▅▂▂▃▃▂▃▆▃▂▁▂▂▂▂▅▃▃▅▂▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/avg_bpp</td><td>0.197</td></tr><tr><td>train/avg_bpp_mv_y</td><td>0.11948</td></tr><tr><td>train/avg_bpp_mv_z</td><td>0.00113</td></tr><tr><td>train/avg_bpp_y</td><td>0.07469</td></tr><tr><td>train/avg_bpp_z</td><td>0.00169</td></tr><tr><td>train/avg_loss</td><td>0.33799</td></tr><tr><td>train/avg_mse_loss</td><td>7e-05</td></tr><tr><td>train/avg_psnr</td><td>41.6214</td></tr><tr><td>train/batch_loss</td><td>0.19661</td></tr><tr><td>train/epoch</td><td>20</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment-variable-quantization-2048-local</strong>: <a href=\"https://wandb.ai/codec-crew/DCVC-Variable-Quantization/runs/3ntr7zs9\" target=\"_blank\">https://wandb.ai/codec-crew/DCVC-Variable-Quantization/runs/3ntr7zs9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220510_040556-3ntr7zs9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44169066c052695af5fd19d9518487adc444660c2346375501c6220f3d24b6a5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dcvc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
