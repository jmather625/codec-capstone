{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa714849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f098242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.DCVC_net import DCVC_net\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bbf444e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BATCH_SIZE = 4\n",
    "# DATA_DIR = pathlib.Path('/data2/jatin/vimeo_septuplet/sequences')\n",
    "DEVICE = torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18cdd0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_net = DCVC_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea66ceb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCVC_net(\n",
       "  (bitEstimator_z): BitEstimator(\n",
       "    (f1): Bitparm()\n",
       "    (f2): Bitparm()\n",
       "    (f3): Bitparm()\n",
       "    (f4): Bitparm()\n",
       "  )\n",
       "  (bitEstimator_z_mv): BitEstimator(\n",
       "    (f1): Bitparm()\n",
       "    (f2): Bitparm()\n",
       "    (f3): Bitparm()\n",
       "    (f4): Bitparm()\n",
       "  )\n",
       "  (feature_extract): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ResBlock(\n",
       "      (relu1): ReLU()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (context_refine): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (relu1): ReLU()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (mvEncoder): Sequential(\n",
       "    (0): Conv2d(2, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): GDN()\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): GDN()\n",
       "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): GDN()\n",
       "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (mvDecoder_part1): Sequential(\n",
       "    (0): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): GDN()\n",
       "    (2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (3): GDN()\n",
       "    (4): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (5): GDN()\n",
       "    (6): ConvTranspose2d(128, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       "  (mvDecoder_part2): Sequential(\n",
       "    (0): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.1)\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.1)\n",
       "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.1)\n",
       "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): LeakyReLU(negative_slope=0.1)\n",
       "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): LeakyReLU(negative_slope=0.1)\n",
       "    (12): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (contextualEncoder): Sequential(\n",
       "    (0): Conv2d(67, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): GDN()\n",
       "    (2): ResBlock_LeakyReLU_0_Point_1(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (4): GDN()\n",
       "    (5): ResBlock_LeakyReLU_0_Point_1(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (7): GDN()\n",
       "    (8): Conv2d(64, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  )\n",
       "  (contextualDecoder_part1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "    (1): GDN()\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "    (3): GDN()\n",
       "    (4): ResBlock_LeakyReLU_0_Point_1(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "    (6): GDN()\n",
       "    (7): ResBlock_LeakyReLU_0_Point_1(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "  )\n",
       "  (contextualDecoder_part2): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ResBlock(\n",
       "      (relu1): ReLU()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (relu1): ReLU()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (priorEncoder): Sequential(\n",
       "    (0): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (4): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  )\n",
       "  (priorDecoder): Sequential(\n",
       "    (0): ConvTranspose2d(64, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): ConvTranspose2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (4): ConvTranspose2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (mvpriorEncoder): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (4): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  )\n",
       "  (mvpriorDecoder): Sequential(\n",
       "    (0): ConvTranspose2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): ConvTranspose2d(64, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (4): ConvTranspose2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (entropy_parameters): Sequential(\n",
       "    (0): Conv2d(384, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (4): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (auto_regressive): MaskedConv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (auto_regressive_mv): MaskedConv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (entropy_parameters_mv): Sequential(\n",
       "    (0): Conv2d(512, 426, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): Conv2d(426, 341, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (4): Conv2d(341, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (temporalPriorEncoder): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): GDN()\n",
       "    (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (3): GDN()\n",
       "    (4): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (5): GDN()\n",
       "    (6): Conv2d(64, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  )\n",
       "  (opticFlow): ME_Spynet(\n",
       "    (moduleBasic): ModuleList(\n",
       "      (0): MEBasic(\n",
       "        (conv1): Conv2d(8, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu2): ReLU()\n",
       "        (conv3): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu3): ReLU()\n",
       "        (conv4): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu4): ReLU()\n",
       "        (conv5): Conv2d(16, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      )\n",
       "      (1): MEBasic(\n",
       "        (conv1): Conv2d(8, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu2): ReLU()\n",
       "        (conv3): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu3): ReLU()\n",
       "        (conv4): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu4): ReLU()\n",
       "        (conv5): Conv2d(16, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      )\n",
       "      (2): MEBasic(\n",
       "        (conv1): Conv2d(8, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu2): ReLU()\n",
       "        (conv3): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu3): ReLU()\n",
       "        (conv4): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu4): ReLU()\n",
       "        (conv5): Conv2d(16, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      )\n",
       "      (3): MEBasic(\n",
       "        (conv1): Conv2d(8, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu2): ReLU()\n",
       "        (conv3): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu3): ReLU()\n",
       "        (conv4): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu4): ReLU()\n",
       "        (conv5): Conv2d(16, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # load the good weights\n",
    "# video_net.opticFlow = torch.load('../DCVC/optflow.pth')\n",
    "# video_net.mvEncoder = torch.load('../DCVC/mvenc.pth')\n",
    "# video_net.mvDecoder_part1 = torch.load('../DCVC/mvDecoder_part1.pth')\n",
    "# video_net.mvDecoder_part2 = torch.load('../DCVC/mvDecoder_part2.pth')\n",
    "# video_net.feature_extract = torch.load('../DCVC/feature_extract.pth')\n",
    "# video_net.context_refine = torch.load('../DCVC/context_refine.pth')\n",
    "# # video_net.contextualDecoder_part1 = torch.load('../DCVC/contextualDecoder_part1.pth')\n",
    "\n",
    "video_net.load_state_dict(torch.load('checkpoints/model_dcvc_quality_3_psnr.pth'))\n",
    "# print('Reminder to load optimizer too')\n",
    "# # optimizer = torch.optim.Adam(video_net.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "# video_net.opticFlow.requires_grad_ = False\n",
    "# video_net.mvEncoder.requires_grad_ = False\n",
    "# video_net.mvDecoder_part1.requires_grad_ = False\n",
    "# video_net.mvDecoder_part2.requires_grad_ = False\n",
    "# video_net.feature_extract.requires_grad_ = False\n",
    "# video_net.context_refine.requires_grad_ = False\n",
    "# # video_net.contextualDecoder_part1.requires_grad_ = False\n",
    "video_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55dceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, crop_size=256, make_p_cut=False, make_b_cut=True, deterministic=False):\n",
    "        if make_b_cut and make_p_cut:\n",
    "            raise ValueError('Can only choose one of B-frames or P-frames')\n",
    "        self.data_dir = data_dir\n",
    "        self.crop_size = crop_size\n",
    "        self.make_p_cut = make_p_cut\n",
    "        self.make_b_cut = make_b_cut\n",
    "        self.deterministic = deterministic\n",
    "        self.all_paths = []\n",
    "        for seq in os.listdir(self.data_dir):\n",
    "            subseq = os.listdir(self.data_dir / seq)\n",
    "            for s in subseq:\n",
    "                self.all_paths.append(self.data_dir / seq / s)\n",
    "        assert len(self.all_paths) == 91701\n",
    "        \n",
    "        self.transforms = torch.nn.Sequential(\n",
    "            transforms.RandomCrop(crop_size)\n",
    "        )\n",
    "       \n",
    "    def __getitem__(self, i):\n",
    "        path = self.all_paths[i]\n",
    "        imgs = []\n",
    "        if self.make_b_cut:\n",
    "            # load two reference frames and the B-frame in the middle\n",
    "            #TODO: implement making this deterministic\n",
    "            interval = np.random.randint(1, 4) # can be 1, 2, or 3\n",
    "            ref1 = plt.imread(path / f'im{1}.png')\n",
    "            ref2 = plt.imread(path / f'im{1 + interval*2}.png')\n",
    "            # this is the B-frame, in the middle\n",
    "            im = plt.imread(path / f'im{1 + interval}.png')\n",
    "            imgs = [ref1, ref2, im]\n",
    "        elif self.make_p_cut:\n",
    "            ref = plt.imread(path / f'im1.png')\n",
    "            im = plt.imread(path / f'im2.png')\n",
    "            imgs = [ref, im]\n",
    "        else:\n",
    "            # load full sequence\n",
    "            for i in range(1, 8):\n",
    "                # should be between [0, 1]\n",
    "                img = plt.imread(path / f'im{i}.png')\n",
    "        \n",
    "        # plt.imread should make inputs in [0, 1] for us\n",
    "        imgs = np.stack(imgs, axis=0)\n",
    "        # bring RGB channels in front\n",
    "        imgs = imgs.transpose(0, 3, 1, 2)\n",
    "        return self.transforms(torch.FloatTensor(imgs))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_paths)\n",
    "\n",
    "ds = VideoDataset(DATA_DIR, make_p_cut=True, make_b_cut=False)\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    ds,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=6,\n",
    "    prefetch_factor=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34ce5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_net = video_net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fbb0176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7944448 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Return number of parameters in a model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(video_net)} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c28ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nan_to_num(x, nan=0.0, posinf=1.0, neginf=-1.0):\n",
    "#     \"\"\"This does not exist in PyTorch 1.7.1 so I had to write it.\"\"\"\n",
    "#     #TODO: make more efficient?\n",
    "#     nans = torch.isnan(x)\n",
    "#     posinfs = torch.isposinf(x)\n",
    "#     neginfs = torch.isneginf(x)\n",
    "#     x[nans] = nan\n",
    "#     x[posinfs] = posinf\n",
    "#     x[neginfs] = neginf\n",
    "#     return x\n",
    "\n",
    "# def handle_back_nan_hook(grad):\n",
    "#     # stop nans, inf, -inf, and large values in general\n",
    "#     grad = nan_to_num(grad, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "#     grad = torch.clip(grad, min=-1.0, max=1.0)\n",
    "#     return grad\n",
    "\n",
    "# for p in video_net.parameters():\n",
    "#     if p.requires_grad:\n",
    "#         p.register_hook(handle_back_nan_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "502d30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, dl, compress):\n",
    "    mse_criterion = torch.nn.MSELoss()\n",
    "    model.eval()\n",
    "    epoch_mse = 0\n",
    "    epoch_bitrate = 0\n",
    "    total_count = 0\n",
    "    pbar = tqdm.tqdm(dl)\n",
    "    for i, x in enumerate(pbar):\n",
    "        x = x.to(DEVICE)\n",
    "        ref = x[:,0]\n",
    "        im = x[:,1]\n",
    "        with torch.no_grad():\n",
    "            preds_dict = model(ref, im, compress=compress)\n",
    "        preds = preds_dict['recon_image']\n",
    "        bpp = preds_dict['bpp']\n",
    "        mse_loss = mse_criterion(preds, im)        \n",
    "        epoch_mse += mse_loss.item()\n",
    "        epoch_bitrate += bpp.item()\n",
    "        total_count += 1\n",
    "        if i % 1 == 0:\n",
    "            avg_mse = epoch_mse / total_count\n",
    "            avg_psnr = -10.0*np.log10(avg_mse)\n",
    "            avg_bitrate = epoch_bitrate / total_count\n",
    "            avg_mse = round(avg_mse, 6)\n",
    "            avg_psnr = round(avg_psnr, 6)\n",
    "            avg_bitrate = round(avg_bitrate, 6)\n",
    "            pbar.set_description(f'Avg PSNR/Bitrate: {avg_psnr, avg_bitrate}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af64058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg PSNR/Bitrate: (41.826272, 0.057603):   4%|▍         | 1004/22926 [02:00<43:56,  8.31it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mtest_epoch\u001b[0;34m(model, dl, compress)\u001b[0m\n\u001b[1;32m     15\u001b[0m bpp \u001b[38;5;241m=\u001b[39m preds_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbpp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m mse_loss \u001b[38;5;241m=\u001b[39m mse_criterion(preds, im)        \n\u001b[0;32m---> 17\u001b[0m epoch_mse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmse_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m epoch_bitrate \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bpp\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     19\u001b[0m total_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_epoch(video_net, dl, compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ca25cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg PSNR/Bitrate: (41.423817, 0.062252):   7%|▋         | 1566/22926 [03:00<41:08,  8.65it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mtest_epoch\u001b[0;34m(model, dl, compress)\u001b[0m\n\u001b[1;32m     15\u001b[0m bpp \u001b[38;5;241m=\u001b[39m preds_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbpp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m mse_loss \u001b[38;5;241m=\u001b[39m mse_criterion(preds, im)        \n\u001b[0;32m---> 17\u001b[0m epoch_mse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmse_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m epoch_bitrate \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bpp\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     19\u001b[0m total_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_epoch(video_net, dl, compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c98b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_net.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcvc",
   "language": "python",
   "name": "dcvc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
